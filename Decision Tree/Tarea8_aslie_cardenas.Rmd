---
title: "Tarea 8"
author: "Aslie Cárdenas Sandoval"
date: "2024-09-25"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(traineR)
library(caret)
library(rpart.plot)
library(knitr)
```


<h2 style="color:#FF1493;">Ejercicio 1</h2>
Esta pregunta utiliza los datos (tumores.csv). Se trata de un conjunto de datos de características del tumor cerebral que incluye cinco variables de primer orden y ocho de textura y cuatro parámetros de evaluación de la calidad con el nivel objetivo. Las variables son: Media, Varianza, Desviación estándar, Asimetría, Kurtosis, Contraste, Energía, ASM (segundo momento angular), Entropía, Homogeneidad, Disimilitud, Correlación, Grosor, PSNR (Pico de la relación señal-ruido), SSIM (Índice de Similitud Estructurada), MSE (Mean Square Error), DC (Coeficiente de Dados) y la variable a predecir tipo (1 = Tumor, 0 = No-Tumor).

<h3 style="color:steelblue;">Ejercicio 1.1</h4>
Cargue la tabla de datos tumores.csv en R y genere en R usando la función createDataPartition(...) del paquete caret la tabla de testing con una 25 % de los datos y con el resto de los datos genere una tabla de aprendizaje.
```{r}
datos.tumores <- read.csv("./DatosTarea8/tumores.csv", header = TRUE, sep = ",", dec = '.', stringsAsFactors = TRUE, row.names = 1)
datos.tumores$tipo <- as.factor(datos.tumores$tipo)
dim(datos.tumores)

set.seed(123) 
muestra <- createDataPartition(y = datos.tumores$tipo, p = 0.75, list = FALSE)

taprendizaje <- datos.tumores[muestra, ]
ttesting <- datos.tumores[-muestra, ]

nrow(taprendizaje)
nrow(ttesting)

```

<br>
<h3 style="color:steelblue;">Ejercicio 1.2</h4>
Usando árboles de Decisión (con traineR) genere un modelo predictivo para la tabla de aprendizaje. Modifique los parámetros del árbol de decisión para lograr los mejores resultados posibles. Grafique el árbol obtenido.
```{r}
modelo.arbol <- train.rpart(tipo~., data=taprendizaje, minsplit = 2)
prediccion.arbol <- predict(modelo.arbol, ttesting, type="class")

prp(modelo.arbol, extra = 104, branch.type = 2, lwd = 1,
    box.col=c("#85c1e9", "#abebc6")[modelo.arbol$frame$yval])

```


<br>
<h3 style="color:steelblue;">Ejercicio 1.3</h4>
Construya una tabla para los índices anteriores que permita comparar el resultado de los árboles de Decisión con respecto a los métodos generados en las tareas anteriores ¿Cuál método es mejor?
```{r}
mc.arbol <- confusion.matrix(ttesting, prediccion.arbol)
indices.arbol <- general.indexes(mc = mc.arbol)
indices.arbol

kmax <- floor(sqrt(nrow(taprendizaje)))
modelo.knn <- train.knn(tipo ~ ., data = taprendizaje, kmax = kmax)
modelo.knn
prediccion.knn <- predict(modelo.knn, ttesting)
mc.knn <- confusion.matrix(ttesting, prediccion.knn)
indices.knn <- general.indexes(mc = mc.knn)

modelo.svm <- train.svm(tipo ~ ., data = taprendizaje)
prediccion.svm <- predict(modelo.svm, ttesting)
mc.svm <- confusion.matrix(ttesting, prediccion.svm)
indices.svm <- general.indexes(mc = mc.svm)


precision.arbol <- indices.arbol$overall.accuracy
error.arbol <- indices.arbol$overall.error
category.accuracy.arbol <- indices.arbol$category.accuracy

precision.knn <- indices.knn$overall.accuracy
error.knn <- indices.knn$overall.error
category.accuracy.knn <- indices.knn$category.accuracy

precision.svm <- indices.svm$overall.accuracy
error.svm <- indices.svm$overall.error
category.accuracy.svm <- indices.svm$category.accuracy


comparacion <- data.frame(
  Método = c("Árbol de decisión", "KNN", "SVM"),
  `Overall Accuracy` = c(precision.arbol, precision.knn, precision.svm),
  `Overall Error` = c(error.arbol, error.knn, error.svm),
  `Category Accuracy 0` = c(category.accuracy.arbol[1], category.accuracy.knn[1], category.accuracy.svm[1]),
  `Category Accuracy 1` = c(category.accuracy.arbol[2], category.accuracy.knn[2], category.accuracy.svm[2])
)

tabla <- kable(comparacion, 
                format = "markdown", 
                caption = "Comparación de Modelos: Árbol de Decisión, KNN y SVM",
                align = "c",
                row.names = FALSE)

tabla

```

El modelo de árbol de decisión es el más efectivo, con alta precisión y bajo error. KNN muestra buena precisión general, pero su desempeño en la categoría 0 es bajo en comparación con el árbol de decisión. SVM tiene la menor precisión global y la peor precisión en la categoría 0.


<h2 style="color:#FF1493;">Ejercicio 2</h2>
Esta pregunta utiliza los datos sobre la conocida historia y tragedia del Titanic, usando los datos titanicV2020.csv de los pasajeros se trata de predecir la supervivencia o no de un pasajero.
La tabla contiene 12 variables y 1309 observaciones, las variables son:

- PassegerId: El código de identificación del pasajero (valor único).
- Survived: Variable a predecir, 1 (el pasajero sobrevivió) 0 (el pasajero no sobrevivió).
- Pclass: En que clase viajaba el pasajero (1 = primera, 2 = segunda , 3 = tercera).
- Name: Nombre del pasajero (valor único).
- Sex: Sexo del pasajero.
- Age: Edad del pasajero.
- SibSp: Cantidad de hermanos o cónyuges a bordo del Titanic.
- Parch: Cantidad de padres o hijos a bordo del Titanic.
- Ticket: Número de tiquete (valor único).
- Fare: Tarifa del pasajero.
- Cabin: Número de cabina (valor único).
- Embarked: Puerto donde embarco el pasajero (C = Cherbourg, Q = Queenstown, S = Southampton).

<h3 style="color:steelblue;">Ejercicio 2.1</h4>
Cargue la tabla de datos titanicV2020.csv, asegúrese re-codificar las variables cualitativas y de ignorar variables que no se deben usar.
```{r}
titanic <- read.csv("./DatosTarea8/titanicV2020.csv", header = TRUE, sep = ",", dec = '.', stringsAsFactors = TRUE, row.names = 1)
titanic$Survived <- factor(titanic$Survived)
titanic$Pclass <- factor(titanic$Pclass, ordered = TRUE)

titanic <- titanic[, !names(titanic) %in% c("Name", "Ticket", "Cabin")]
titanic <- na.omit(titanic)
str(titanic)
```


<br>
<h3 style="color:steelblue;">Ejercicio 2.2</h4>
Usando el comando sample de R genere al azar una tabla aprendizaje con un 80 % de los datos y con el resto de los datos genere una tabla de aprendizaje.
```{r}
set.seed(123)
n <- nrow(titanic)
muestra <- sample(1:n, size = floor(n * 0.80))
aprendizaje.titanic <- titanic[muestra, ]
testing.titanic <- titanic[-muestra, ]

testing.titanic$Sex <- factor(testing.titanic$Sex, levels = levels(aprendizaje.titanic$Sex))
testing.titanic$Embarked <- factor(testing.titanic$Embarked, levels = levels(aprendizaje.titanic$Embarked))

```


<br>
<h3 style="color:steelblue;">Ejercicio 2.3</h4>
Usando árboles de Decisión (con traineR) genere un modelo predictivo para la tabla de aprendizaje. Modifique los parámetros del árbol de decisión para lograr los mejores resultados posibles. Grafique el árbol obtenido.
```{r}
modelo.arbol.titanic <- train.rpart(Survived~., data=aprendizaje.titanic, minsplit = 2)
prediccion.arbol.titanic <- predict(modelo.arbol.titanic, testing.titanic, type="class")

prp(modelo.arbol.titanic, 
    extra = 104, 
    branch.type = 2, 
    lwd = 1,
    box.col = c("#85c1e9", "#abebc6")[modelo.arbol.titanic$frame$yval])               
```

Para pasajeros masculinos:

- Si la edad es >= 5 años, tiene una baja probabilidad de supervivencia (0.12 o 12%).
- Si la edad es < 5 años, se considera la clase del pasajero:
  - Si es de tercera clase, hay una probabilidad de supervivencia de 0.31 o 31%.
  - Si es primera o segunda, hay una probabilidad de supervivencia de 0.89 o 89%.
 

Para pasajeros femeninos:

- Si es de primera o segunda clase, hay una probabilidad de supervivencia de 0.97 o 97%. 
- Si es de tercera clase, se examina el precio del boleto:
  - Si el precio del boleto es >= 21, hay una probabilidad de supervivencia de 0.24 o 24%.
  - Si el precio del boleto es < 21, hay una probabilidad de supervivencia de 0.76 o 76%.

Azul: Indica una mayor probabilidad de no sobrevivir (0).

Verde: Indica una mayor probabilidad de sobrevivir (1).

<br>
<h3 style="color:steelblue;">Ejercicio 2.4</h4>
Construya una tabla para los índices anteriores que permita comparar el resultado de los árboles de Decisión con respecto a los métodos generados en las tareas anteriores ¿Cuál método es mejor?

```{r}
mc.arbol.titanic <- confusion.matrix(testing.titanic, prediccion.arbol.titanic)
indices.arbol.titanic <- general.indexes(mc = mc.arbol.titanic)

kmax <- floor(sqrt(nrow(aprendizaje.titanic)))
modelo.knn.titanic <- train.knn(Survived ~ ., data = aprendizaje.titanic, kmax = kmax)
prediccion.knn.titanic <- predict(modelo.knn.titanic, testing.titanic)
mc.knn.titanic <- confusion.matrix(testing.titanic, prediccion.knn.titanic)
indices.knn.titanic <- general.indexes(mc = mc.knn.titanic)

modelo.svm.titanic <- train.svm(Survived ~ ., data = aprendizaje.titanic)
prediccion.svm.titanic <- predict(modelo.svm.titanic, testing.titanic)
mc.svm.titanic <- confusion.matrix(testing.titanic, prediccion.svm.titanic)
indices.svm.titanic <- general.indexes(mc = mc.svm.titanic)


precision.arbol.titanic <- indices.arbol.titanic$overall.accuracy
error.arbol.titanic <- indices.arbol.titanic$overall.error
category.accuracy.arbol.titanic <- indices.arbol.titanic$category.accuracy

precision.knn.titanic <- indices.knn.titanic$overall.accuracy
error.knn.titanic <- indices.knn.titanic$overall.error
category.accuracy.knn.titanic <- indices.knn.titanic$category.accuracy

precision.svm.titanic <- indices.svm.titanic$overall.accuracy
error.svm.titanic <- indices.svm.titanic$overall.error
category.accuracy.svm.titanic <- indices.svm.titanic$category.accuracy


comparacion.titanic <- data.frame(
  Método = c("Árbol de decisión", "KNN", "SVM"),
  `Overall Accuracy` = c(precision.arbol.titanic, precision.knn.titanic, precision.svm.titanic),
  `Overall Error` = c(error.arbol.titanic, error.knn.titanic, error.svm.titanic),
  `Category Accuracy 0` = c(category.accuracy.arbol.titanic[1], category.accuracy.knn.titanic[1], category.accuracy.svm.titanic[1]),
  `Category Accuracy 1` = c(category.accuracy.arbol.titanic[2], category.accuracy.knn.titanic[2], category.accuracy.svm.titanic[2])
)

tabla.titanic <- kable(comparacion.titanic, 
                format = "markdown", 
                caption = "Comparación de Modelos: Árbol de Decisión, KNN y SVM",
                align = "c",
                row.names = FALSE)

tabla.titanic

```
- El modelo de Árbol de decisión tuvo la mejor precisión global y la mayor precisión en la categoría 0, aunque su precisión en la categoría 1 fue la segunda más baja entre los modelos.

- KNN mostró un desempeño intermedio en comparación con los otros dos modelos, con precisiones razonablemente equilibradas entre ambas categorías.

- SVM tuvo una precisión global similar a KNN, pero su rendimiento fue inferior en la categoría 1.

<h2 style="color:#FF1493;">Ejercicio 3</h2>
En este ejercicio vamos a predecir números escritos a mano (Hand Written Digit Recognition), la tabla de de datos está en el archivo ZipData 2020.csv.

<h3 style="color:steelblue;">Ejercicio 3.1</h4>
Cargue la tabla de datos ZipData 2020.csv en R.
```{r}
datos.numeros <- read.csv("./DatosTarea8/ZipData_2020.csv", header = TRUE, sep = ";", dec = '.', stringsAsFactors = TRUE)
dim(datos.numeros)
```


<br>
<h3 style="color:steelblue;">Ejercicio 3.2</h4>
Use el método de Arboles de Decisión con el método y los parámetros que usted considere más conveniente para generar un modelo predictivo para la tabla ZipData 2020.csv usando el 80 % de los datos para la tabla aprendizaje y un 20 % para la tabla testing, luego calcule para los datos de testing la matriz de confusión, la precisión global y la precisión para cada una de las categorías. ¿Son buenos los resultados? Explique
```{r}
set.seed(123)  
muestra.numeros <- createDataPartition(y = datos.numeros$Numero, p = 0.8, list = F)
taprendizaje.num <- datos.numeros[muestra.numeros, ]
ttesting.num <- datos.numeros[-muestra.numeros, ]

modelo.arbol.numero <- train.rpart(Numero ~ ., data = taprendizaje.num, minsplit = 2)

prediccion <- predict(modelo.arbol.numero, ttesting.num, type = "class")


mc.arbol.numeros <- confusion.matrix(ttesting.num, prediccion)
indices.arbol.numeros <- general.indexes(mc = mc.arbol.numeros)
indices.arbol.numeros

```
Los resultados no son los mejores, pero son pasables, es bueno. Sin embargo, algunas categorías como cinco 53.85% y ocho 58.87% tienen un rendimiento más bajo en comparación con otras como cero 87.74% y uno 95.65%.

<br>
<h3 style="color:steelblue;">Ejercicio 3.3</h4>
Compare los resultados con los obtenidos en las tareas anteriores.
```{r}
kmax <- floor(sqrt(nrow(taprendizaje.num)))
modelo.knn.numeros <- train.knn(Numero~., data = taprendizaje.num, kmax = kmax)
prediccion.knn.numeros <- predict(modelo.knn.numeros, ttesting.num)
mc.knn.numeros <- confusion.matrix(ttesting.num, prediccion.knn.numeros)
indice.knn.numeros <- general.indexes(mc = mc.knn.numeros)


modelo.svm.numeros <- train.svm(Numero ~ ., data = taprendizaje.num)
prediccion.svm.numeros <- predict(modelo.svm.numeros, ttesting.num)
mc.svm.numeros <- confusion.matrix(ttesting.num, prediccion.svm.numeros)
indices.svm.numeros <- general.indexes(mc = mc.svm.numeros)

precision.arbol.numeros <- indices.arbol.numeros$overall.accuracy
error.arbol.numeros <- indices.arbol.numeros$overall.error
category.accuracy.arbol.numeros <- indices.arbol.numeros$category.accuracy

precision.knn.numeros <- indice.knn.numeros$overall.accuracy
error.knn.numeros <- indice.knn.numeros$overall.error
category.accuracy.knn.numeros <- indice.knn.numeros$category.accuracy

precision.svm.numeros <- indices.svm.numeros$overall.accuracy
error.svm.numeros <- indices.svm.numeros$overall.error
category.accuracy.svm.numeros <- indices.svm.numeros$category.accuracy

indices.arbol.numeros
indice.knn.numeros
indices.svm.numeros

comparacion.numeros <- data.frame(
  Método = c("Árbol de decisión", "KNN", "SVM"),
  `Overall Accuracy` = c(precision.arbol.numeros, precision.knn.numeros, precision.svm.numeros),
  `Overall Error` = c(error.arbol.numeros, error.knn.numeros, error.svm.numeros)
  
)


comparacion.numeros <- kable(comparacion.numeros, 
                format = "markdown", 
                caption = "Comparación de Modelos: Árbol de Decisión, KNN y SVM",
                align = "c",
                row.names = FALSE)

comparacion.numeros

```
- SVM es el mejor modelo con la mejor precisión general del 96.76% y un error general del 3.24%.
- KNN es el segundo mejor modelo con una precisión general del 95.90% y un error del 4.10%.
- Árbol de Decisión es el peor modelo con una precisión general del 74.33% y un error del 25.67%.

- KNN y SVM muestran un rendimiento notablemente superior en comparación con el Árbol de Decisión, especialmente en la precisión por categoría, donde KNN se destaca en casi todas las categorías.
- El modelo de Árbol de Decisión tiene dificultades significativas, especialmente con la categoría cinco, lo que se refleja en su baja precisión (53.85%).


Para la Tabla de Datos que se muestra seguidamente (la variable a predecir es Tipo):
```{r}
data <- data.frame(
  Tipo = c(1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0),
  Color = c("Amarillo", "Amarillo", "Amarillo", "Azul", "Azul", "Azul", "Azul", "Amarillo", "Azul", "Azul", "Azul"),
  Tamaño = c("Grande", "Grande", "Pequeño", "Pequeño", "Grande", "Grande", "Pequeño", "Pequeño", "Pequeño", "Grande", "Grande")
)

data

```




<h2 style="color:#FF1493;">Ejercicio 4</h2>
<h3 style="color:steelblue;">Ejercicio 4.1</h4>
Calcule la información ganada usando el índice Gini para las 2 posibles divisiones (iniciando con la variable Color o iniciando con la variable Tamaño) ¿Cuál división es la mejor? ¿Por qué?

**<span style="color: orange;">Índice Gini del conjunto inicial:</span>**

**<span style="color: orange;">Total de instancias: 11</span>**  
**<span style="color: orange;">Clase 1: 5 instancias</span>**  
**<span style="color: orange;">Clase 0: 6 instancias</span>**


Gini(S) = 1 - (5/11)^2 - (6/10)^2 = 0.495

**<span style="color: pink;">- División por Color:</span>**


  - Amarillo (4 instancias): 3 de clase 1, 1 de clase 0
  - Gini(Amarillo) = 1 - (3/4)^2 - (1/4)^2 = 0.375

  - Azul (7 instancias): 2 de clase 1, 5 de clase 0
  - Gini(Azul) = 1 - (2/7)^2 - (5/7)^2 = 0.408

  - Gini ponderado = (4/11 * 0.375) + (7/11 * 0.408) = 0.396

  - Información ganada (Color) = 0.495 - 0.396 = 0.099

**<span style="color: skyblue;">- División por Tamaño:</span>**


  - Grande (6 instancias): 3 de clase 1, 3 de clase 0
  - Gini(Grande) = 1 - (3/6)^2 - (3/6)^2 = 0.5

  - Pequeño (5 instancias): 2 de clase 1, 3 de clase 0
  - Gini(Pequeño) = 1 - (2/5)^2 - (3/5)^2 = 0.48

  - Gini ponderado = (6/11 * 0,5) + (5/11 * 0.48) = 0,490
  - Información ganada (Tamaño) = 0.495 - 0.490 = 0.005

La división por Color proporciona mayor información ganada, por lo que sería la mejor opción para dividir el conjunto de datos según el criterio del índice Gini.

<br>
<h3 style="color:steelblue;">Ejercicio 4.2</h4>
De acuerdo al resultado del ítem anterior, genere el árbol que representa todas las reglas de decisión. En caso de nodos hoja donde exista un empate en las clases de la variable a predecir puede clasificar como usted desee. Puede utilizar cualquier herramienta para dibujar el árbol, inclusive puede hacerlo a mano. El dibujo debe ser completamente legible.

![Árbol de Decisión](./DatosTarea8/arbol.png)

