---
title: "Tarea 6"
author: "Aslie Cárdenas Sandoval"
date: "2024-09-11"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


<h2 style="color:#FF1493;">Ejercicio 1</h2>
Dada la Tabla de Testing de un Scoring de Crédito


<h3 style="color:steelblue;">Ejercicio 1.1</h4>
Usando la columna BuenPagador en donde aparece el verdadero valor de la variable a predecir y la columna PrediccionKNN en donde aparece la predicción del Método KNN para esta tabla de Testing, calcule la Matriz de Confusión.

Conteo de casos:

- Verdaderos Positivos (VP): BuenPagador = Sí, PrediccionKNN = Sí
- Falsos Positivos (FP): BuenPagador = No, PrediccionKNN = Sí
- Falsos Negativos (FN): BuenPagador = Sí, PrediccionKNN = No
- Verdaderos Negativos (VN): BuenPagador = No, PrediccionKNN = No

Por lo tanto:

- VP = 16
- FP = 3
- FN = 2
- VN = 4
```{r cache=TRUE}
matriz.confusión <- matrix(c(4, 2, 3, 16), nrow = 2, ncol = 2, byrow = TRUE)
rownames(matriz.confusión) <- c("Mal Pagador", "Buen Pagador")
colnames(matriz.confusión) <- c("Mal Pagador", "Buen Pagador")
print(matriz.confusión)

```
De 25 casos, el modelo acertó en 20 (16 + 4) y se equivocó en 5 (3 + 2).
El modelo predijo correctamente 16 buenos pagadores y 4 malos pagadores.


<h3 style="color:steelblue;">Ejercicio 1.2</h4>
Con la Matriz de Confusión anterior calcule “a mano” la Precisión Global, el Error Global, la Precisión Positiva (PP), la Precisión Negativa (PN), la Proporción de Falsos Positivos (PFP), la Proporción de Falsos Negativos (PFN), la Asertividad Positiva (AP) y la Asertividad Negativa (AN).

- **PG: (VN+VP)/(VN+FP+FN+VP)** ⇒ 4+16/4+2+3+16 ⇒ 20/25 ⇒ 0.8 ⇒ 80%
- **Error Global: (FP + FN)/(VN+FP+FN+VP)** ⇒ 3+2/4+2+3+16 ⇒ 5/25 ⇒ 0.2 ⇒ 20%
- **PP (Porcentaje de Verdaderos Positivos): VP/(FN+VP)** ⇒ 16/2+16 ⇒ 16/18 ⇒ 0.88 ⇒ 88%
- **PN (Casos negativos que fueron identificados correctamente): VN/(VN+FP)** ⇒ 4/4+3 ⇒ 4/7 ⇒ 0.57 ⇒ 57%
- **PFP (Casos negativos que fueron clasificados incorrectamente): FP/(VN+FP)** ⇒ 3/4+3 ⇒ 3/7 ⇒ 0.42 ⇒ 42%
- **PFN (Casos positivos que fueron clasificados incorrectamente): FN/(FN+VP)** ⇒ 2/2+16 ⇒ 2/18 ⇒ 0.11 ⇒ 11%
- **AP (Buena predicción para los positivos): VP/(FP+VP)** ⇒ 16/3+16 ⇒ 16/19 ⇒ 0.84 ⇒ 84%
- **AN (Buena predicción para los negativos): VN/(VN+FN)** ⇒ 4/4+2 ⇒ 4/6 ⇒ 0.66 ⇒ 66%



<h2 style="color:#FF1493;">Ejercicio 2</h2>

<h3 style="color:steelblue;">Ejercicio 2.1</h4>
Programe en lenguaje R una función que reciba como entrada la matriz de confusión (para el caso 2 × 2) que calcule y retorne en una lista: la Precisión Global, el Error Global, la Precisión Positiva (PP), la Precisión Negativa (PN), los Falsos Positivos (FP), los Falsos Negativos (FN), la Asertividad Positiva (AP) y la Asertividad Negativa (NP).

```{r cache=TRUE}
indices.confusion <- function(MC) {
  if (nrow(MC) != ncol(MC)) {
    stop("La matriz de confusión debe ser cuadrada.")
  }
  
  precision.global <- sum(diag(MC)) / sum(MC)
  error.global <- 1 - precision.global
  precision.categoria <- diag(MC) / rowSums(MC)
  
 
  VP <- MC[2,2]  # Verdaderos Positivos
  FP <- MC[1,2]  # Falsos Positivos
  FN <- MC[2,1]  # Falsos Negativos
  VN <- MC[1,1]  # Verdaderos Negativos
  
  precision.positiva <- VP / (VP + FN)
  precision.negativa <- VN / (VN + FP)
  proporcion.falsos.positivos <- FP / (VN + FP)
  proporcion.falsos.negativos <- FN / (VP + FN)
  asertividad.positiva <- VP / (VP + FP)
  asertividad.negativa <- VN / (VN + FN)
  
  res <- list(
    matriz.confusion = MC,
    precision.global = precision.global,
    error.global = error.global,
    precision.categoria = precision.categoria,
    precision.positiva = precision.positiva,
    precision.negativa = precision.negativa,
    falsos.positivos = proporcion.falsos.positivos,
    falsos.negativos = proporcion.falsos.negativos,
    asertividad.positiva = asertividad.positiva,
    asertividad.negativa = asertividad.negativa
  )
  
  
  names(res) <- c(
    "Matriz de Confusión", "Precisión Global", "Error Global",
    "Precisión por categoría", "Precisión Positiva", "Precisión Negativa",
    "Falsos Positivos", "Falsos Negativos", "Asertividad Positiva", "Asertividad Negativa"
  )
  
  return(res)
}

```


<br>
<h3 style="color:steelblue;">Ejercicio 2.2</h4>
Supongamos que tenemos un modelo predictivo para detectar Fraude en Tarjetas de Crédito, la variable a predecir es Fraude con dos posibles valores Sí (para el caso en que sí fue fraude) y No (para el caso en que no fue fraude). Supongamos la matriz de confusión es:
• Calcule la Precisión Global, el Error Global, la Precisión Positiva (PP), la Precisión Negativa (PN), los Falsos Positivos (FP), los Falsos Negativos (FN), la Asertividad Positiva (AP) y la Asertividad Negativa (NP).
```{r cache=TRUE}
MC <- matrix(c(892254, 212, 8993, 300), nrow = 2, byrow = TRUE)
rownames(MC) <- c("No", "Sí")
colnames(MC) <- c("No", "Sí")
resultados <- indices.confusion(MC)


print(resultados)
```

• ¿Es bueno o malo el modelo predictivo? Justifique su respuesta.

- El modelo tiene una alta precisión global y bajo error global, lo que significa que en general está clasificando bien los casos y parece bueno a primera vista. Sin embargo, el hecho de que la precisión positiva sea tan baja y la proporción de falsos negativos sea tan alta indica que el modelo está fallando en la tarea de detectar el fraude.

- En cuanto a a la presicion positiva(3,32%) el modelo tiene mucha dificultad para identificar casos de fraude. Solo detecta correctamente una pequeña parte de los fraudes y en la presion negativa(96%) el modelo es muy bueno para identificar casos que no son fraude, pero esto no es lo más importante en la detección de fraude.

- La proporción de falsos positivos es muy baja(0.02%), lo que es bueno para evitar alarmas falsas, pero la proporción de falsos negativos es extremadamente alta(96.77%). Esto significa que el modelo está fallando en detectar la mayoría de los casos de fraude. En un contexto de fraude en tarjetas de crédito, esto es crítico, ya que la detección de fraude es crucial.

- La asertividad positiva(58.60%), que indica la proporción de verdaderos positivos entre todos los casos reales positivos, es relativamente baja. Esto refuerza la idea de que el modelo no está detectando bien el fraude. La asertividad Negativa (99.00%) es alta, lo que es bueno, pero puede ser engañoso si el modelo no está identificando bien los casos positivos.


<h2 style="color:#FF1493;">Ejercicio 3</h2>
Esta pregunta utiliza los datos (tumores.csv). Se trata de un conjunto de datos de características del tumor cerebral que incluye cinco variables de primer orden y ocho de textura y cuatro parámetros de evaluación de la calidad con el nivel objetivo. Las variables son: Media, Varianza, Desviación estándar, Asimetría, Kurtosis, Contraste, Energía, ASM (segundo momento angular), Entropía, Homogeneidad, Disimilitud, Correlación, Grosor, PSNR (Pico de la relación señal-ruido), SSIM (Índice de Similitud Estructurada), MSE (Mean Square Error), DC (Coeficiente de Dados) y la variable a predecir tipo (1 = Tumor, 0 = No-Tumor).



<h3 style="color:steelblue;">Ejercicio 3.1</h4>
Use el método de K vecinos más cercanos en el paquete traineR para generar un modelo predictivo para la tabla tumores.csv usando el 75 % de los datos para la tabla aprendizaje y un 25 % para la tabla testing. No olvide recodificar, desde R, la variable a predecir como
categórica
```{r cache=TRUE}
library(traineR)
library(caret)

datos.tumores <- read.csv("./DatosTarea6/tumores.csv", header = TRUE, sep = ",", dec = '.', stringsAsFactors = TRUE, row.names = 1)
datos.tumores$tipo <- as.factor(datos.tumores$tipo)

n <- nrow(datos.tumores)

set.seed(123)
muestra <- sample(1:n, size = floor(n * 0.75))
taprendizaje <- datos.tumores[muestra, ]
ttesting <- datos.tumores[-muestra, ]

# Ajustar el modelo KNN con la función correcta del paquete traineR
kmax <- floor(sqrt(nrow(taprendizaje)))
modelo.knn <- train.knn(tipo ~ ., data = taprendizaje, kmax = kmax)
modelo.knn

num_train <- nrow(taprendizaje)
cat("Número de observaciones en el conjunto de entrenamiento:", num_train, "\n")
num_test <- nrow(ttesting)
cat("Número de observaciones en el conjunto de prueba:", num_test, "\n")
total <- num_train + num_test
cat("Porcentaje de datos en el conjunto de entrenamiento:", (num_train / total) * 100, "%\n")
cat("Porcentaje de datos en el conjunto de prueba:", (num_test / total) * 100, "%\n")

barplot(prop.table(table(datos.tumores$tipo)),col=c("#f71e6c","#2197a3"),main="Distribución de la variable a predecir")
```


<br>
<h3 style="color:steelblue;">Ejercicio 3.2</h4>
Genere un Modelo Predictivo usando K vecinos más cercanos para cada uno de los siguientes núcleos: rectangular, triangular, epanechnikov, biweight, triweight, cos, inv, gaussian y optimal ¿Cuál produce los mejores resultados en el sentido de que predice mejor los tumores, es decir, Tumor = 1.
```{r cache=TRUE}
nucleos <- c("rectangular", "triangular", "epanechnikov", "biweight", "triweight", "cos", "inv", "gaussian", "optimal")

calcular.precision.tumores <- function(valor.real, prediccion, nucleo) {
  matriz.conf <- table(valor.real, prediccion)
  cat("\nMatriz de Confusión usando el núcleo:", nucleo, "\n")
  print(matriz.conf)

  # '1' es el valor de Tumor, mientras que '0' es No-Tumor
  VP <- matriz.conf["1", "1"]
  FP <- matriz.conf["0", "1"]

  precision <- VP / (VP + FP)
  return(precision)
}

resultados <- data.frame(nucleo = nucleos, precision = numeric(length(nucleos)))

for (i in seq_along(nucleos)) {
  modelo.knn <- train.knn(tipo ~ ., data = taprendizaje, kmax = kmax, kernel = nucleos[i])
  
  predicciones <- predict(modelo.knn, newdata = ttesting)
  
  precision <- calcular.precision.tumores(ttesting$tipo, predicciones$prediction, nucleos[i])
  
  resultados$precision[i] <- precision
}

# Ordenar resultados por precisión descendente
resultados <- resultados[order(-resultados$precision),]
print(resultados)

mejor_nucleo <- resultados$nucleo[1]
cat("El núcleo que produce los mejores resultados es:", mejor_nucleo, 
    "con una precisión de", round(resultados$precision[1], 4), 
    "para predecir tumores malignos.\n")

```


<h2 style="color:#FF1493;">Ejercicio 4</h2>
Esta pregunta utiliza los datos sobre la conocida historia y tragedia del Titanic, usando los datos titanicV2020.csv de los pasajeros se trata de predecir la supervivencia o no de un pasajero.
La tabla contiene 12 variables y 1309 observaciones, las variables son:

- PassegerId: El código de identificación del pasajero (valor único).
- Survived: Variable a predecir, 1 (el pasajero sobrevivió) 0 (el pasajero no sobrevivió).
- Pclass: En que clase viajaba el pasajero (1 = primera, 2 = segunda , 3 = tercera).
- Name: Nombre del pasajero (valor único).
- Sex: Sexo del pasajero.
- Age: Edad del pasajero.
- SibSp: Cantidad de hermanos o cónyuges a bordo del Titanic.
- Parch: Cantidad de padres o hijos a bordo del Titanic.
- Ticket: Número de tiquete (valor único).
- Fare: Tarifa del pasajero.
- Cabin: Número de cabina (valor único).
- Embarked: Puerto donde embarco el pasajero (C = Cherbourg, Q = Queenstown, S = Southampton).

<h3 style="color:steelblue;">Ejercicio 4.1</h4>
Cargue la tabla de datos titanicV2020.csv, asegúrese re-codificar las variables cualitativas y de ignorar variables que no se deben usar.
```{r cache=TRUE}
datos.titanic <- read.csv("./DatosTarea6/titanicV2020.csv", header = TRUE, sep = ",", dec = '.', stringsAsFactors = TRUE, row.names = 1)
datos.titanic$Survived <- as.factor(datos.titanic$Survived)
datos.titanic$Pclass <- factor(datos.titanic$Pclass, ordered = TRUE)

datos.titanic <- datos.titanic[, !names(datos.titanic) %in% c("Name", "Ticket", "Cabin")]

str(datos.titanic)

```


<br>
<h3 style="color:steelblue;">Ejercicio 4.2</h4>
Realice un análisis exploratorio (estadísticas básicas) que incluya: el resumen numérico(media, desviación estándar, etc.), los valores atípicos, la correlación entre las variables, el poder predictivo de las variables predictoras. Interprete los resultados.
```{r cache=TRUE}
install.packages("ggplot2")
library(ggplot2)
library(dplyr)
library(scales)
library(glue)


summary(datos.titanic)

datos.titanic$Age[is.na(datos.titanic$Age)] <- median(datos.titanic$Age, na.rm = TRUE)
datos.titanic$Fare[is.na(datos.titanic$Fare)] <- median(datos.titanic$Fare, na.rm = TRUE)

```
```{r cache=TRUE}
library(ggplot2)
ggplot(datos.titanic, aes(x = "", y = Age)) +
  geom_boxplot(fill = "#c8b9f7", color = "#a58aff", outlier.colour = "#c8b9f7", outlier.size = 2) +
  labs(title = "Boxplot de Edad", 
       x = "", 
       y = "Edad") +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5, size = 14, face = "bold"), 
        axis.title.y = element_text(size = 12), 
        axis.text.y = element_text(size = 10)) 

ggplot(datos.titanic, aes(x = "", y = Fare)) +
  geom_boxplot(fill = "#fdd3f4", color = "#fa68d8", outlier.colour = "#fdd3f4", outlier.size = 2) +
  labs(title = "Boxplot de Tarifa", 
       x = "", 
       y = "Tarifa") +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5, size = 14, face = "bold"), 
        axis.title.y = element_text(size = 12), 
        axis.text.y = element_text(size = 10)) 


```

Interpretación: 

- El rango de edad va desde cerca de 0 hasta alrededor de 80 años, con la mayoría de los datos concentrados entre 20 y 40 años.

- El rango de tarifa va desde cerca de 0 hasta alrededor de 500, hay varios valores atípicos en la parte superior, lo que suguiere a tarifas más elevadas al promedio.

```{r cache=TRUE}
library(corrplot)
datos.numericos <- datos.titanic[, sapply(datos.titanic, is.numeric)]
correlacion.titanic <- cor(datos.numericos, use = "complete.obs")
correlacion.titanic
corrplot(correlacion.titanic, addCoef.col = 'black', col = COL2("PiYG", 10), tl.col = "black")

```

- No hay correlación fuerte entre edad y tarifa.
- Hay correlación positiva entre SibSp y Partch lo que refiere a familiares a bordo, si viajaban con hermanos o conyuges, también había más posibilidad de que también viajaran con hijos o padres.
- La edad tiene una relación negativa débil con el número de familiares a bordo, sugiriendo que los pasajeros más jóvenes tienden a viajar con más familiares.
- Las tarifas tienen una relación positiva débil con todas las variables, indicando una ligera tendencia a ser más altas para pasajeros de mayor edad o con más familiares.


```{r cache=TRUE}
equilibrio.variable.predecir <- function(datos, variable.predecir, ylab = "Cantidad de individuos", 
                                        xlab = "", main = paste("Distribución de la variable",variable.predecir), col = NA) {
  gg_color <- function (n) {
     hues <- seq(15, 375, length = n + 1)
     hcl(h = hues, l = 65, c = 100)[1:n]
  }
  if(missing(variable.predecir) | !(variable.predecir %in% colnames(datos))){
    stop("variable.predecir tiene que ser ingresada y ser un nombre de columna", call. = FALSE )
  }
  if(is.character(datos[,variable.predecir]) | is.factor(datos[,variable.predecir])){
    if(length(col) == 0 || is.na(col)){
      col <- gg_color(length(unique(datos[,variable.predecir])))
    }else{
      col <- rep(col,length(unique(datos[,variable.predecir])))
    }
    ggplot(data = datos, mapping = aes_string(x = variable.predecir, fill = variable.predecir)) +
      geom_bar() +
      scale_fill_manual(values = col, name = variable.predecir) +
      labs(x = xlab, y = ylab, title = main) +
      theme_minimal() +
      theme(legend.position = "bottom")
  }else{
    stop("La variable a predecir tienen que ser de tipo factor o character", call. = FALSE )
  }
}

poder.predictivo.numerica <- function(datos, variable.predecir, variable.comparar, ylab = "", 
                                       xlab = "", main = paste("Densidad de la variable", variable.comparar, 'según', variable.predecir), col = NA){
  gg_color <- function (n) {
     hues <- seq(15, 375, length = n + 1)
     hcl(h = hues, l = 65, c = 100)[1:n]
  }
  if(missing(variable.predecir) | !(variable.predecir %in% colnames(datos))){
    stop("variable.predecir tiene que ser ingresada y ser un nombre de columna", call. = FALSE )
  }
  if(missing(variable.comparar) | !(variable.comparar %in% colnames(datos)) | !is.numeric(datos[,variable.comparar])){
    stop("variable.comparar tiene que ser ingresada y ser un nombre de columna numérica", call. = FALSE )
  }
  
  if(is.character(datos[,variable.predecir]) | is.factor(datos[,variable.predecir])){
    if(length(col) == 0 || is.na(col)){
      col <- gg_color(length(unique(datos[,variable.predecir])))
    }else{
      col <- rep(col,length(unique(datos[,variable.predecir])))
    }
    
    ggplot(data = datos, aes_string(variable.comparar, fill = variable.predecir)) +
      geom_density(alpha = .7, color = NA) +
      scale_fill_manual(values = col) +
      labs(title = main , y = ylab, x = xlab ,fill = variable.predecir) +
      theme_minimal() +
      theme(legend.position = 'bottom',
            legend.title = element_blank(),
            text = element_text(size = 15))
    
  }else{
    stop("La variable a predecir tienen que ser de tipo factor o character", call. = FALSE )
  }
}

poder.predictivo.categorica <- function(datos, variable.predecir, variable.comparar, ylab = "", 
                                        xlab = "", main = paste("Densidad de la variable", variable.comparar, 'según', variable.predecir), col = NA) {
  library(scales)  # Asegúrate de cargar la librería scales
  
  gg_color <- function(n) {
    hues <- seq(15, 375, length = n + 1)
    hcl(h = hues, l = 65, c = 100)[1:n]
  }
  
  if (missing(variable.predecir) || !(variable.predecir %in% colnames(datos))) {
    stop("variable.predecir tiene que ser ingresada y ser un nombre de columna", call. = FALSE)
  }
  
  if (missing(variable.comparar) || !(variable.comparar %in% colnames(datos)) || 
      !(is.factor(datos[[variable.comparar]]) || is.character(datos[[variable.comparar]]))) {
    stop("variable.comparar tiene que ser ingresada y ser un nombre de columna categórica", call. = FALSE)
  }
  
  if (is.character(datos[[variable.predecir]]) || is.factor(datos[[variable.predecir]])) {
    if (length(col) == 0 || is.na(col)) {
      col <- gg_color(length(unique(datos[[variable.predecir]])))
    } else {
      col <- rep(col, length(unique(datos[[variable.predecir]])))
    }
    
    datos2 <- datos %>%
      dplyr::group_by(across(all_of(variable.comparar)), across(all_of(variable.predecir))) %>%
      dplyr::summarise(count = n(), .groups = 'drop')
    
    if (variable.comparar != variable.predecir) {
      datos2 <- datos2 %>% dplyr::group_by(across(all_of(variable.comparar)))
    }
    
    datos2 <- datos2 %>%
      dplyr::mutate(prop = round(count / sum(count), 4))
    
    ggplot(data = datos2, mapping = aes_string(x = variable.comparar, y = "prop", fill = variable.predecir)) +
      geom_col(position = "fill") +
      geom_text(aes(label = glue::glue("{scales::percent(prop)} ({count})")), position = position_stack(vjust = .5), color = "white") +
      scale_y_continuous(labels = scales::percent) +
      labs(y = xlab, x = ylab, title = main) +
      scale_fill_manual(values = col, name = variable.predecir) +
      theme(legend.position = "bottom") +
      coord_flip()
  } else {
    stop("La variable a predecir tiene que ser de tipo factor o character", call. = FALSE)
  }
}
# Índices para matrices NxN
indices.general <- function(MC) {
  precision.global <- sum(diag(MC))/sum(MC)
  error.global <- 1 - precision.global
  precision.categoria <- diag(MC)/rowSums(MC)
  res <- list(matriz.confusion = MC, precision.global = precision.global, error.global = error.global, 
              precision.categoria = precision.categoria)
  names(res) <- c("Matriz de Confusión", "Precisión Global", "Error Global", 
                  "Precisión por categoría")
  return(res)
}


numericas <- c("Age", "SibSp", "Parch", "Fare")

for (var in numericas) {
  print(paste("Análisis del poder predictivo de la variable:", var))
  print(poder.predictivo.numerica(datos.titanic, "Survived", var))
}

categoricas <- c("Pclass", "Sex", "Embarked")

for (var in categoricas) {
  print(paste("Análisis del poder predictivo de la variable:", var))
  print(poder.predictivo.categorica(datos.titanic, "Survived", var))
}
```

Interpretación del poder predictivo de las variables predictoras:

Variables númericas:

- Edad: La edad de los pasajeros muestra una ligera diferencia en la probabilidad de supervivencia, pero en general, los patrones son similares. Sin embargo, se observa una tendencia importante: los más pequeños, probablemente niños tienen una mayor probabilidad de sobrevivir en comparación con los adultos. Esto sugiere que la edad puede tener una influencia significativa en la supervivencia, destacando la prioridad de rescate para los menores de edad.

- SibSp (Número de hermanos o cónyuges a bordo) y Parch (Número de padres o hijos a bordo): Las variables SibSp y Parch no muestran diferencias significativas entre las categorías en relación con la supervivencia. La presencia de familiares a bordo no parece tener un impacto claro en la probabilidad de sobrevivencia, lo que indica que estas variables tienen una menor influencia predictiva en el resultado de la supervivencia.

- Tarifa (Fare): La tarifa pagada por el pasajero es un factor importante en la probabilidad de supervivencia. Los pasajeros que pagaron tarifas más altas tienen una mayor probabilidad de sobrevivir, lo que sugiere que el nivel socioeconómico puede haber influido en las oportunidades de supervivencia durante el desastre.

- Poder Predictivo General: En general, las variables como SibSp y Parch tienen un poder predictivo limitado para la supervivencia, ya que sus categorías no muestran un patrón claro en la supervivencia. La variable Edad, aunque tiene cierta influencia, no es tan determinante en la supervivencia como la Tarifa. La variable Tarifa demuestra un mayor poder predictivo debido a su clara relación con la probabilidad de supervivencia. 

Variables categóricas:

- Pclass: Muestra una fuerte relación con la supervivencia. Los pasajeros de primera clase tenían una probabilidad significativamente mayor de sobrevivir en comparación con los de tercera clase. Esta variable tiene un alto poder predictivo para la supervivencia, dado el patrón que se observa en los datos.

- Sex: Hay una diferencia muy significativa en las tasas de supervivencia entre hombres y mujeres. Las mujeres tenían una probabilidad mucho mayor de sobrevivir que los hombres.
El sexo es un predictor muy fuerte de la supervivencia en el Titanic.

- Embarked: El puerto de embarque también muestra cierta relación con la supervivencia, aunque menos pronunciada que el sexo. Los pasajeros que embarcaron en Cherbourg tuvieron la mejor tasa de supervivencia. Los que embarcaron en Southampton tuvieron la peor tasa de supervivencia.

- Poder Predictivo General: Las tres variables parecen tener poder predictivo para la supervivencia, pero el sexo se destaca como un factor más determinante.

<br>
<h3 style="color:steelblue;">Ejercicio 4.3</h4>
¿Es este problema equilibrado o desequilibrado? Justifique su respuesta.
```{r cache=TRUE}
equilibrio.variable.predecir(datos.titanic, "Survived")
```

Este problema es desequilibrado, ya que hay una diferencia significativa entre el número de individuos que no sobrevivieron y los que sí lo hicieron.


<br>
<h3 style="color:steelblue;">Ejercicio 4.4</h4>
Use el método de K vecinos más cercanos en el paquete traineR, con los parámetros que logren el mejor resultado, para generar un modelo predictivo con la tabla titanicV2020.csv usando el 80 % de los datos para la tabla aprendizaje y un 20 % para la tabla testing, luego calcule para los datos de testing la matriz de confusión, la precisión global y la precisión para cada una de las dos categorías. ¿Son buenos los resultados? Explique.
```{r cache=TRUE}
library(traineR)
library(caret)
library(ggplot2)
library(lattice)

indices.confusion2 <- function(MC) {
  if (nrow(MC) != ncol(MC)) {
    stop("La matriz de confusión debe ser cuadrada.")
  }
  
  precision.global <- sum(diag(MC)) / sum(MC)
  error.global <- 1 - precision.global
  precision.categoria <- diag(MC) / rowSums(MC)
  
  VP <- MC[2,2]  # Verdaderos Positivos
  FP <- MC[1,2]  # Falsos Positivos
  FN <- MC[2,1]  # Falsos Negativos
  VN <- MC[1,1]  # Verdaderos Negativos
  
  precision.positiva <- VP / (VP + FN)
  precision.negativa <- VN / (VN + FP)
  proporcion.falsos.positivos <- FP / (VN + FP)
  proporcion.falsos.negativos <- FN / (VP + FN)
  asertividad.positiva <- VP / (VP + FP)
  asertividad.negativa <- VN / (VN + FN)
  
  res <- list(
    matriz.confusion = MC,
    precision.global = precision.global,
    error.global = error.global,
    precision.categoria = precision.categoria,
    precision.positiva = precision.positiva,
    precision.negativa = precision.negativa,
    falsos.positivos = proporcion.falsos.positivos,
    falsos.negativos = proporcion.falsos.negativos,
    asertividad.positiva = asertividad.positiva,
    asertividad.negativa = asertividad.negativa
  )
  
  names(res) <- c(
    "Matriz de Confusión", "Precisión Global", "Error Global",
    "Precisión por categoría", "Precisión Positiva", "Precisión Negativa",
    "Falsos Positivos", "Falsos Negativos", "Asertividad Positiva", "Asertividad Negativa"
  )
  
  return(res)
}


n <- nrow(datos.titanic)
tamano.prueba <- floor(n * 0.20)

set.seed(123) 
muestra <- sample(1:n, tamano.prueba)

ttesting2 <- datos.titanic[muestra, ]
taprendizaje2 <- datos.titanic[-muestra, ]

# Entrenar el modelo KNN
modelo.titanic <- train.knn(Survived~., data = taprendizaje2, kmax = floor(sqrt(n)))
print(modelo.titanic)

num.train2 <- nrow(taprendizaje2)
num.test2 <- nrow(ttesting2)
cat("Número de observaciones en el conjunto de entrenamiento:", num.train2, "\n")
cat("Número de observaciones en el conjunto de prueba:", num.test2, "\n")

total <- num.train2 + num.test2
cat("Porcentaje de datos en el conjunto de entrenamiento:", (num.train2 / total) * 100, "%\n")
cat("Porcentaje de datos en el conjunto de prueba:", (num.test2 / total) * 100, "%\n")

prediccion <- predict(modelo.titanic, ttesting2)
head(prediccion)

MC <- confusion.matrix(ttesting2, prediccion)

indices1 <- indices.confusion2(MC)
indices1
```
- La precisión global del 85.06% indica que el modelo es bastante bueno para clasificar correctamente tanto a los que sobrevivieron como a los que no sobrevivieron. Esto sugiere que el modelo tiene un buen rendimiento general.

- El error global del 14.94% es bajo, el modelo es eficiente en la mayoría de los casos. 

- Precisión para 0 (no sobrevivió): 91.61%, el modelo es muy bueno para predecir a los pasajeros que no sobrevivieron. La mayoría de las predicciones en esta categoría son correctas.

- Precisión para 1 (sobrevivió): 75.47% muestra que el modelo es algo menos efectivo para predecir a los pasajeros que sobrevivieron. Aunque es razonablemente bueno, hay margen para mejorar en esta categoría.

- La precisión para la categoría 1 es algo menor y esto puede deberse al desbalance en la cantidad de ejemplos de las dos categorías.

<br>
<h3 style="color:steelblue;">Ejercicio 4.5</h4>
Repita el item 4), pero esta vez, seleccione las 5 variables que, según su criterio, tienen mejor poder predictivo. ¿Mejoran los resultados?
```{r cache=TRUE}
n <- nrow(datos.titanic)
tamano.prueba <- floor(n * 0.20)

set.seed(123) 
muestra <- sample(1:n, tamano.prueba)

ttesting2 <- datos.titanic[muestra, ]
taprendizaje2 <- datos.titanic[-muestra, ]

# Entrenar el modelo KNN
modelo.titanic2 <- train.knn(Survived ~ Pclass + Sex + Embarked + Age + Fare, data = taprendizaje2, kmax = floor(sqrt(n)))
print(modelo.titanic2)

prediccion2 <- predict(modelo.titanic2, ttesting2)
head(prediccion)

MC2 <- confusion.matrix(ttesting2, prediccion2)

indices2 <- indices.confusion2(MC2)
indices2
```
- La precisión global ha aumentado del 85.06% al 86.21%, lo que indica una mejora general en la capacidad del modelo para clasificar correctamente las observaciones.

- La precisión para la clase 0 (No sobrevivió) ha aumentado de 91.61% a 92.90%, lo que sugiere una mejor capacidad del modelo para identificar correctamente los casos en los que los pasajeros no sobrevivieron.

- La precisión para la clase 1 (Sobrevivió) ha aumentado de 75.47% a 76.42%, indicando también una mejora en la identificación de los casos en los que los pasajeros sobrevivieron.

<br>
<h3 style="color:steelblue;">Ejercicio 4.6</h4>
Usando la función programada en el ejercicio 1, los datos titanicV2020.csv y los modelos generados arriba construya un DataFrame de manera que en cada una de las filas aparezca un modelo predictivo y en las columnas aparezcan los índices Precisión Global, Error
Global Precisión Positiva (PP), Precisión Negativa (PN), Falsos Positivos (FP), los Falsos Negativos (FN), la Asertividad Positiva (AP) y la Asertividad Negativa (AN). ¿Cuál de los modelos es mejor para estos datos?
```{r cache=TRUE}
library(knitr)
resultados <- data.frame(
  Modelo = c("Modelo 1", "Modelo 2"),
  `Precisión Global` = c(indices1$`Precisión Global`, indices2$`Precisión Global`),
  `Error Global` = c(indices1$`Error Global`, indices2$`Error Global`),
  `Precisión Positiva` = c(indices1$`Precisión Positiva`, indices2$`Precisión Positiva`),
  `Precisión Negativa` = c(indices1$`Precisión Negativa`, indices2$`Precisión Negativa`),
  `Falsos Positivos` = c(indices1$`Falsos Positivos`, indices2$`Falsos Positivos`),
  `Falsos Negativos` = c(indices1$`Falsos Negativos`, indices2$`Falsos Negativos`),
  `Asertividad Positiva` = c(indices1$`Asertividad Positiva`, indices2$`Asertividad Positiva`),
  `Asertividad Negativa` = c(indices1$`Asertividad Negativa`, indices2$`Asertividad Negativa`)
)

kable(resultados, caption = "Resultados de Modelos Predictivos")

```


- El Modelo 2 es mejor, ya que tiene mayor precisión global (86.21% vs. 85.06%), menor error global, y una precisión positiva y negativa ligeramente superiores, lo que indica un mejor rendimiento general en la predicción.

<h2 style="color:#FF1493;">Ejercicio 5</h2>
En este ejercicio vamos a predecir números escritos a mano (Hand Written Digit Recognition), la tabla de de datos está en el archivo ZipData 2020.csv. Los datos de este ejemplo vienen de los códigos postales escritos a mano en sobres del correo postal de EE.UU. Las imágenes son de 16 × 16 en escala de grises, cada píxel va de intensidad de −1 a 1 (de blanco a negro). Las imágenes se han normalizado para tener aproximadamente
el mismo tamaño y orientación. La tarea consiste en predecir, a partir de la matriz de 16 × 16 de intensidades de cada píxel, la identidad de cada imagen (0, 1, . . . , 9) de forma rápida y precisa. Si es lo suficientemente precisa, el algoritmo resultante se utiliza como parte de un
procedimiento de selección automática para sobres. Este es un problema de clasificación para el cual la tasa de error debe mantenerse muy baja para evitar la mala dirección de correo. La columna 1 tiene la variable a predecir Número codificada como sigue: 0=‘cero’; 1=‘uno’; 2=‘dos’;
3=‘tres’; 4=‘cuatro’; 5=‘cinco’;6=‘seis’; 7=‘siete’; 8=‘ocho’ y 9=‘nueve’, las demás columnas son las variables predictivas, además cada fila de la tabla representa un bloque 16 × 16 por lo que la matriz tiene 256 variables predictivas.

<h3 style="color:steelblue;">Ejercicio 5.1</h4>
Cargue la tabla de datos ZipData_2020.csv en R.
```{r cache=TRUE}
datos.numeros <- read.csv("./DatosTarea6/ZipData_2020.csv", header = TRUE, sep = ";", dec = '.', stringsAsFactors = TRUE)
dim(datos.numeros)
```
<br>
<h3 style="color:steelblue;">Ejercicio 5.2</h4>
¿Es este problema equilibrado o desequilibrado? Justifique su respuesta.
```{r cache=TRUE}
equilibrio.variable.predecir(datos.numeros, "Numero")
```

- Este problema es desequilibrado ya que hay una distribución desigual en la cantidad de individuos entre las diferentes categorías. Algunas categorías tienen muchos más individuos que otras como las categorías cero y uno que tienen una cantidad significativamente mayor de individuos (alrededor de 1500 y 1250 respectivamente) en comparación con otras como cinco y ocho que tienen menos de la mitad de individuos.

<br>
<h3 style="color:steelblue;">Ejercicio 5.3</h4>
Use el método de K vecinos más cercanos en el paquete traineR (con los parámetros por defecto) para generar un modelo predictivo para la tabla ZipData 2020.csv usando el 80 % de los datos para la tabla aprendizaje y un 20 % para la tabla testing, luego calcule para los datos de testing la matriz de confusión, la precisión global y la precisión para cada una de las categorías. ¿Son buenos los resultados? Explique.
```{r cache=TRUE}
n <- nrow(datos.numeros)
tamano.prueba3 <- floor(n * 0.20)

set.seed(123) 
muestra.numeros <- sample(1:n, tamano.prueba3)

ttesting3 <- datos.numeros[muestra.numeros, ]
taprendizaje3 <- datos.numeros[-muestra.numeros, ]

# Entrenar el modelo KNN
modelo.numeros <- train.knn(Numero~., data = taprendizaje3, kmax = floor(sqrt(n)))
print(modelo.numeros)

num.train3 <- nrow(taprendizaje3)
num.test3 <- nrow(ttesting3)
cat("Número de observaciones en el conjunto de entrenamiento:", num.train3, "\n")

cat("Número de observaciones en el conjunto de prueba:", num.test3, "\n")

total3 <- num.train3 + num.test3
cat("Porcentaje de datos en el conjunto de entrenamiento:", (num.train3 / total3) * 100, "%\n")

cat("Porcentaje de datos en el conjunto de prueba:", (num.test3 / total3) * 100, "%\n")

prediccion3 <- predict(modelo.numeros, ttesting3)
head(prediccion$prediction)
MC3 <- confusion.matrix(ttesting3, prediccion3)
general.indexes(mc = MC3)
```

- Los resultados son excelentes, con una precisión global cercana al 96% y con un error global de solo 3.82%, lo que sugiere que el modelo comete pocos errores en sus predicciones, también la precisión por categoría es muy alta, lo que indica que el modelo tiene un buen desempeño para todas las categorías. Esto sugiere que el modelo está bien ajustado, con pocos errores tanto globalmente como en la mayoría de las categorías individuales.